{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1rTDj7R_NF1g1WmhW32zfrIMdfeLbh1qe",
      "authorship_tag": "ABX9TyPLbciW2ODpGhltQ0Y2UIKZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/0x-alex-s/autograder/blob/main/autograder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional environment check\n",
        "from psutil import *\n",
        "print(\"Number of CPU: \", cpu_count())\n",
        "!cat /proc/cpuinfo"
      ],
      "metadata": {
        "id": "zkk66V1MKok2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wrap output for reading more conveniently\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "metadata": {
        "id": "-0LBdueNxACe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies not available in Colab environment and download SpaCy large dataset\n",
        "!pip install python-dotenv langchain_mistralai\n",
        "\n",
        "import spacy.cli\n",
        "spacy.cli.download(\"en_core_web_lg\")"
      ],
      "metadata": {
        "id": "P4woe7Nx4XyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "load_dotenv('/content/drive/MyDrive/Colab Notebooks/.env')\n",
        "mistral_key = os.getenv('MISTRAL_KEY')"
      ],
      "metadata": {
        "id": "NSSpG4cN4v6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-P-1P2QxmsL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "f39fcc88-0cfc-4e37-e6d2-9fab7b620314"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from collections import Counter\n",
        "from string import punctuation\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import spacy\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "from scipy.stats import percentileofscore\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "class Grader:\n",
        "    def __init__(self, model_name = \"sentence-transformers/all-mpnet-base-v2\"):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.model = AutoModel.from_pretrained(model_name)\n",
        "        self.nlp = spacy.load('en_core_web_lg')\n",
        "\n",
        "    def _get_embedding(self, text: str) -> np.ndarray:\n",
        "        inputs = self.tokenizer(text, padding=True, truncation=True,\n",
        "                              return_tensors=\"pt\", max_length=512)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(**inputs)\n",
        "\n",
        "        attention_mask = inputs['attention_mask']\n",
        "        token_embeddings = outputs.last_hidden_state\n",
        "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "        sentence_embedding = torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "\n",
        "        return sentence_embedding.numpy()\n",
        "\n",
        "    def _calculate_coherence(self, answer: str) -> float:\n",
        "        doc = self.nlp(answer)\n",
        "        sentences = list(doc.sents)\n",
        "\n",
        "        if len(sentences) < 2:\n",
        "            return 1.0\n",
        "\n",
        "        coherence_scores = []\n",
        "        for i in range(len(sentences) - 1):\n",
        "            sent1_embed = self._get_embedding(sentences[i].text)\n",
        "            sent2_embed = self._get_embedding(sentences[i + 1].text)\n",
        "            similarity = cosine_similarity(sent1_embed, sent2_embed)[0][0]\n",
        "            coherence_scores.append(similarity)\n",
        "\n",
        "        return np.mean(coherence_scores)\n",
        "\n",
        "    def assess_answer(self,\n",
        "                     student_answer: str,\n",
        "                     model_answer: str,\n",
        "                     rubric = None):\n",
        "\n",
        "        student_embedding = self._get_embedding(student_answer)\n",
        "        model_embedding = self._get_embedding(model_answer)\n",
        "\n",
        "        similarity_score = cosine_similarity(student_embedding, model_embedding)[0][0]\n",
        "\n",
        "        coherence_score = self._calculate_coherence(student_answer)\n",
        "\n",
        "        weights = rubric.get('weights', {'similarity': 0.4, 'coherence': 0.2}) if rubric else {\n",
        "            'similarity': 0.4, 'coherence': 0.2\n",
        "        }\n",
        "\n",
        "        final_score = ( weights['similarity'] * similarity_score + weights['coherence'] * coherence_score)\n",
        "\n",
        "        return {\n",
        "            \"similarity_score\": similarity_score,\n",
        "            \"coherence_score\": coherence_score,\n",
        "            \"final_score\": final_score,\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assessor = Grader()\n",
        "\n",
        "# Example question and answers\n",
        "benchmark_answer = \"\"\"\n",
        "    A solution to track items in real-time and share this information with customers.\n",
        "    Optimize routes so we can reduce unnecessary driving and fuel consumption.\n",
        "    With RFID-technology for tracking instead of barcodes one can achieve faster and\n",
        "    more efficient real-time tracking that often require a person to scan every code by hand.\n",
        "    \"\"\"\n",
        "\n",
        "student_answer = \"\"\"\n",
        "I would propose making a software who can predict the traffic and make the most efficient\n",
        "delivery route based on available information from cameras and such. And for the real-time\n",
        "tracking problem, I would suggest that the customer can see where the vehicle delivering the\n",
        "package is real-time. Giving every package a trackable chip of some sort would be very\n",
        "expensive, but of course if the customer is willing to pay for, that could be a solution as well.\n",
        "    \"\"\"\n",
        "\n",
        "rubric = {\n",
        "        'weights': {\n",
        "            'similarity': 0.7,\n",
        "            'coherence': 0.3\n",
        "        }\n",
        "    }\n",
        "\n",
        "result = assessor.assess_answer(student_answer, benchmark_answer, rubric)\n",
        "\n",
        "print(f\"Similarity Score: {result['similarity_score']:.2f}\")\n",
        "print(f\"Coherence Score: {result['coherence_score']:.2f}\")\n",
        "print(f\"Final Score: {result['final_score']:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "1ZwM3_2q085M",
        "outputId": "4c8f1386-f152-4d80-8e62-eb2f5c0e4a81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity Score: 0.46\n",
            "Coherence Score: 0.40\n",
            "Final Score: 0.44\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from langchain_mistralai import ChatMistralAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "from tenacity import retry, stop_after_attempt, wait_exponential\n",
        "\n",
        "class LLMEnhancedAssessor:\n",
        "    def __init__(self, base_assessor, api_key, model = \"mistral-large-latest\"):\n",
        "\n",
        "        self.base_assessor = base_assessor\n",
        "        self.model = model\n",
        "        self.llm = ChatMistralAI(\n",
        "            model_name=model,\n",
        "            mistral_api_key=api_key,\n",
        "            temperature=0\n",
        "        )\n",
        "\n",
        "    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))\n",
        "    async def _generate_llm_analysis(self, student_answer, benchmark_answer, base_assessment):\n",
        "\n",
        "        analysis_prompt = ChatPromptTemplate.from_messages([\n",
        "            (\"system\", \"You are an experienced teaching assistant. Your task is to provide constructive and detailed feedback.\"),\n",
        "            (\"user\", \"\"\"\n",
        "            Analyze student's answer based on the following inputs.\n",
        "\n",
        "            Benchmark Answer: {benchmark_answer}\n",
        "            Student Answer: {student_answer}\n",
        "\n",
        "            Answer scores:\n",
        "            - Similarity to benchmark answer: {similarity_score}\n",
        "            - Coherence: {coherence_score}\n",
        "\n",
        "            Respond in a conversational manner from second person point of view. Start with a detailed conceptual analysis,\n",
        "            then highlight specific areas of strength and areas for improvement, followed by personalized learning suggestions.\n",
        "            Do not split into sections. Use bullet lists as necessary. No greeting. No introductory paragraph. No formatting.\n",
        "            \"\"\")\n",
        "        ])\n",
        "\n",
        "        chain = analysis_prompt | self.llm\n",
        "\n",
        "        result = await chain.ainvoke({\n",
        "            \"benchmark_answer\": benchmark_answer,\n",
        "            \"student_answer\": student_answer,\n",
        "            \"similarity_score\": base_assessment['similarity_score'],\n",
        "            \"coherence_score\": base_assessment['coherence_score']\n",
        "        })\n",
        "\n",
        "        return result\n",
        "\n",
        "    async def generate_feedback(self, student_answer, benchmark_answer):\n",
        "\n",
        "        rubric = {\n",
        "          'weights': {\n",
        "              'similarity': 0.7,\n",
        "              'coherence': 0.3\n",
        "          }\n",
        "        }\n",
        "\n",
        "        base_result = self.base_assessor.assess_answer(\n",
        "            student_answer, benchmark_answer, rubric\n",
        "        )\n",
        "\n",
        "        llm_analysis = await self._generate_llm_analysis(\n",
        "            student_answer,\n",
        "            benchmark_answer,\n",
        "            base_result,\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"score\": base_result['final_score'],\n",
        "            \"tutor_feedback\": llm_analysis.content,\n",
        "        }"
      ],
      "metadata": {
        "id": "b82suA6y2T7J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "26ea846b-6305-4c30-e501-069b0f667c77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_assessor = Grader()\n",
        "\n",
        "rubric = {\n",
        "        'weights': {\n",
        "            'similarity': 0.7,\n",
        "            'coherence': 0.3\n",
        "        }\n",
        "    }\n",
        "\n",
        "enhanced_assessor = LLMEnhancedAssessor(\n",
        "        base_assessor=base_assessor,\n",
        "        api_key=mistral_key\n",
        "    )\n",
        "\n",
        "benchmark_answer = \"\"\"\n",
        "    SDG 13 climate action (reduce emissions) and SDG 8 (decent work and economic growth). May be SDG 11 as well (smart cities and communities). G12 (responsible consumption and production), G9: industry, innovations and infrastructure.  SDG 17 which is “partnerships to reach a goal”.\n",
        "    \"\"\"\n",
        "\n",
        "student_answer = \"\"\"\n",
        "My solutions will positively impact SDG goal number 11 and 13. Number 11 because my\n",
        "solution require Iots, and I don’tsee anything wrong in sharing the information we are\n",
        "gathering for the traffic software with rest of the city if it can help the environment.Number\n",
        "13 because the software makes the transport more efficient, less Co2 is released from the\n",
        "transport vehicles, helpingwith stopping global warming.\n",
        "    \"\"\"\n",
        "\n",
        "result = await enhanced_assessor.generate_feedback(\n",
        "        student_answer=student_answer,\n",
        "        benchmark_answer=benchmark_answer,\n",
        "    )\n",
        "\n",
        "print(f\"Score: {result['score']:.2f}\")\n",
        "print(result['tutor_feedback'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "2D8-hVh12nMn",
        "outputId": "26690e41-4773-4438-92a6-dc43d2791c38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: 0.49\n",
            "Your answer partially aligns with the benchmark answer, as you've identified SDG 13 (Climate Action) and SDG 11 (Sustainable Cities and Communities) as areas your solution would impact. However, the benchmark answer also includes SDG 8, 9, 12, and 17, which you haven't mentioned. Let's break down your response to identify areas of strength and areas for improvement.\n",
            "\n",
            "Conceptually, you've understood that your solution contributes to making cities more sustainable and combating climate change. This is evident in your explanation of how your traffic software can help reduce CO2 emissions, which is a key aspect of SDG 13. You've also understood the role of IoT in creating smart cities, which aligns with SDG 11. However, you've missed out on the broader implications of your solution:\n",
            "\n",
            "- **Strengths:**\n",
            "  - You've clearly explained how your solution directly impacts SDG 13 by reducing emissions.\n",
            "  - You've identified that your use of IoT relates to SDG 11.\n",
            "  - You've expressed your idea clearly and concisely.\n",
            "\n",
            "- **Areas for Improvement:**\n",
            "  - You haven't considered the potential impact of your solution on economic growth and job creation (SDG 8). For instance, your software could create new jobs in tech maintenance and data analysis.\n",
            "  - You haven't touched on the potential of your solution to promote responsible consumption and production (SDG 12). For example, it could optimize fuel use and reduce waste.\n",
            "  - You haven't recognized how your solution might advance industry, innovation, and infrastructure (SDG 9). Your software could be seen as a technological innovation that improves infrastructure.\n",
            "  - You haven't mentioned the importance of partnerships for achieving these goals (SDG 17). Consider how collaborations with local governments, tech companies, or other stakeholders could enhance your solution's impact.\n",
            "  - Your explanation for how your solution relates to SDG 11 is somewhat vague. Simply using IoT isn't enough to contribute to this goal. You should explain how your solution could improve urban planning, accessibility, or other aspects of sustainable cities.\n",
            "  - Some of your sentences are run-on sentences or sentence fragments, which can make your writing less clear.\n",
            "\n",
            "To improve, consider the following:\n",
            "\n",
            "- **Broadening your Perspective:** Think about the wider implications of your solution. How might it create jobs, stimulate economic growth, or promote responsible consumption? What kinds of partnerships could enhance its impact?\n",
            "- **Deepening your Analysis:** Don't just identify which SDGs your solution might impact. Explain how and why. What specific targets within each SDG does your solution address?\n",
            "- **Improving your Writing:** Work on your sentence structure and punctuation to make your writing clearer. Read your sentences aloud to check if they make sense.\n",
            "- **Reflecting on the SDGs:** Familiarize yourself more with the SDGs and their specific targets. This will help you identify more connections between your solution and the SDGs.\n",
            "\n",
            "Remember, the SDGs are interconnected, so it's important to think about how your solution might have ripple effects. Keep up the good work, and with a little more thought and analysis, you'll be well on your way to creating meaningful solutions for the SDGs!\n"
          ]
        }
      ]
    }
  ]
}